{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a3bd0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting ShadowAudit POC on 10 files...\n",
      "Processing ID: img1...\n",
      "  ‚ö†Ô∏è No significant shadows found.\n",
      "Processing ID: img10...\n",
      "  ‚úÖ Found 8 Buildings with Shadows.\n",
      "     - Bld 5: 1 Floors (3.66m)\n",
      "     - Bld 7: 1 Floors (1.69m)\n",
      "     - Bld 19: 1 Floors (3.38m)\n",
      "  üì∏ Evidence saved to: evidence_reports\\evidence_img10.png\n",
      "Processing ID: img1002...\n",
      "  ‚ö†Ô∏è No significant shadows found.\n",
      "Processing ID: img1003...\n",
      "  ‚úÖ Found 6 Buildings with Shadows.\n",
      "     - Bld 1: 5 Floors (17.18m)\n",
      "     - Bld 3: 4 Floors (14.37m)\n",
      "     - Bld 5: 4 Floors (13.24m)\n",
      "  üì∏ Evidence saved to: evidence_reports\\evidence_img1003.png\n",
      "Processing ID: img1004...\n",
      "  ‚úÖ Found 12 Buildings with Shadows.\n",
      "     - Bld 11: 5 Floors (16.62m)\n",
      "     - Bld 3: 4 Floors (12.40m)\n",
      "     - Bld 6: 4 Floors (13.52m)\n",
      "  üì∏ Evidence saved to: evidence_reports\\evidence_img1004.png\n",
      "Processing ID: img1006...\n",
      "  ‚úÖ Found 12 Buildings with Shadows.\n",
      "     - Bld 7: 7 Floors (23.95m)\n",
      "     - Bld 15: 5 Floors (14.93m)\n",
      "     - Bld 16: 5 Floors (16.90m)\n",
      "  üì∏ Evidence saved to: evidence_reports\\evidence_img1006.png\n",
      "Processing ID: img1007...\n",
      "  ‚úÖ Found 23 Buildings with Shadows.\n",
      "     - Bld 32: 7 Floors (22.82m)\n",
      "     - Bld 13: 4 Floors (11.27m)\n",
      "     - Bld 21: 4 Floors (12.96m)\n",
      "  üì∏ Evidence saved to: evidence_reports\\evidence_img1007.png\n",
      "Processing ID: img1009...\n",
      "  ‚úÖ Found 26 Buildings with Shadows.\n",
      "     - Bld 37: 7 Floors (21.41m)\n",
      "     - Bld 2: 5 Floors (16.34m)\n",
      "     - Bld 4: 5 Floors (16.62m)\n",
      "  üì∏ Evidence saved to: evidence_reports\\evidence_img1009.png\n",
      "Processing ID: img101...\n",
      "  ‚úÖ Found 14 Buildings with Shadows.\n",
      "     - Bld 7: 4 Floors (13.80m)\n",
      "     - Bld 9: 4 Floors (12.68m)\n",
      "     - Bld 10: 4 Floors (11.83m)\n",
      "  üì∏ Evidence saved to: evidence_reports\\evidence_img101.png\n",
      "Processing ID: img1010...\n",
      "  ‚úÖ Found 10 Buildings with Shadows.\n",
      "     - Bld 3: 3 Floors (9.30m)\n",
      "     - Bld 4: 2 Floors (6.20m)\n",
      "     - Bld 5: 2 Floors (5.63m)\n",
      "  üì∏ Evidence saved to: evidence_reports\\evidence_img1010.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "import geopandas as gpd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION: LAS VEGAS (SpaceNet AOI 2)\n",
    "# ==========================================\n",
    "CONFIG = {\n",
    "    \"SUN_AZIMUTH\": 170.5,       # Direction of shadow (Degrees)\n",
    "    \"SUN_ELEVATION\": 43.2,      # Sun height (Degrees)\n",
    "    \"PIXEL_RES\": 0.3,           # Meters per pixel (WorldView-3)\n",
    "    \"FLOOR_HEIGHT\": 3.2,        # Avg height of a floor (meters)\n",
    "    \"MIN_SHADOW_PX\": 5,         # Noise filter (ignore tiny blobs)\n",
    "    \"SEARCH_DIST_M\": 25.0,      # Search zone length (meters)\n",
    "    \"IMG_DIR\": \"PS-RGB\",        # Input Folder (Images)\n",
    "    \"LABEL_DIR\": \"geojson_buildings\", # Input Folder (Footprints)\n",
    "    \"OUTPUT_DIR\": \"evidence_reports\"  # Output Folder\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# MODULE 1: ROBUST NORMALIZATION\n",
    "# ==========================================\n",
    "def normalize_to_8bit_robust(img_16bit):\n",
    "    \"\"\"\n",
    "    Converts 16-bit satellite data to 8-bit for OpenCV.\n",
    "    Uses Percentile Clipping (1%-99%) to fix the 'Black Image' issue.\n",
    "    \"\"\"\n",
    "    img = np.ascontiguousarray(img_16bit)\n",
    "    low_val = np.percentile(img, 1)\n",
    "    high_val = np.percentile(img, 99)\n",
    "    img_clipped = np.clip(img, low_val, high_val)\n",
    "    img_8bit = cv2.normalize(img_clipped, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    return img_8bit\n",
    "\n",
    "# ==========================================\n",
    "# MODULE 2: SHADOW DETECTION (TSAI)\n",
    "# ==========================================\n",
    "def tsai_shadow_detection(img_rgb):\n",
    "    \"\"\"\n",
    "    Implementation of Tsai (2006) Spectral Ratio Algorithm.\n",
    "    Includes Contrast Stretching to work in low-contrast environments (Deserts).\n",
    "    \"\"\"\n",
    "    # 1. Convert to HLS (Hue, Lightness, Saturation)\n",
    "    hls = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HLS)\n",
    "    H, L, S = cv2.split(hls)\n",
    "    \n",
    "    # 2. Normalize components\n",
    "    H_norm = H.astype(float) / 179.0\n",
    "    I_norm = L.astype(float) / 255.0\n",
    "    \n",
    "    # 3. Calculate Spectral Ratio\n",
    "    # Formula: (Hue + 1) / (Intensity + 1)\n",
    "    ratio = (H_norm + 1) / (I_norm + 0.05)\n",
    "    \n",
    "    # 4. Contrast Stretching (The \"Boost\")\n",
    "    # Forces the ratio map to use the full 0-255 range\n",
    "    ratio_norm = cv2.normalize(ratio, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    ratio_norm = np.uint8(ratio_norm)\n",
    "    \n",
    "    # 5. Otsu's Thresholding\n",
    "    _, shadow_mask = cv2.threshold(ratio_norm, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # 6. Cleanup (Morphological Opening)\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    clean_mask = cv2.morphologyEx(shadow_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    \n",
    "    return clean_mask\n",
    "\n",
    "# ==========================================\n",
    "# MODULE 3: EVIDENCE (PARALLEL LINE SCAN)\n",
    "# ==========================================\n",
    "def parallel_line_scan(shadow_mask, sun_azimuth):\n",
    "    \"\"\"\n",
    "    The 'Parallel Scan' method from Gavankar (Paper 8).\n",
    "    Rotates the shadow and scans for the maximum continuous length.\n",
    "    \"\"\"\n",
    "    rows, cols = shadow_mask.shape\n",
    "    \n",
    "    # Rotate shadow to align with X-axis (remove Sun Angle)\n",
    "    shadow_dir = (sun_azimuth + 180) % 360\n",
    "    center = (cols // 2, rows // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, -shadow_dir, 1.0)\n",
    "    rotated = cv2.warpAffine(shadow_mask, M, (cols, rows))\n",
    "    \n",
    "    max_len_px = 0\n",
    "    \n",
    "    # Scan every 2nd row\n",
    "    for y in range(0, rows, 2):\n",
    "        if np.sum(rotated[y, :]) == 0: continue\n",
    "        \n",
    "        contours, _ = cv2.findContours(rotated[y:y+1, :], cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for cnt in contours:\n",
    "            length = cv2.arcLength(cnt, True) / 2\n",
    "            if length > max_len_px:\n",
    "                max_len_px = length\n",
    "                \n",
    "    return max_len_px\n",
    "\n",
    "# ==========================================\n",
    "# MODULE 4: MAIN PIPELINE\n",
    "# ==========================================\n",
    "def process_tile(tif_path, geojson_path, save_evidence=True):\n",
    "    base_id = os.path.basename(tif_path).split('_')[-1].replace('.tif', '')\n",
    "    print(f\"Processing ID: {base_id}...\")\n",
    "    \n",
    "    # 1. Load Data\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        img_raw = src.read([1, 2, 3])\n",
    "        img_raw = np.moveaxis(img_raw, 0, -1)\n",
    "        img_8bit = normalize_to_8bit_robust(img_raw)\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "    \n",
    "    try:\n",
    "        gdf = gpd.read_file(geojson_path)\n",
    "        if gdf.crs != crs: gdf = gdf.to_crs(crs)\n",
    "    except:\n",
    "        print(\"  ‚ùå GeoJSON Error\")\n",
    "        return\n",
    "\n",
    "    # 2. Run Shadow Detection (Tsai)\n",
    "    global_shadow_mask = tsai_shadow_detection(img_8bit)\n",
    "    \n",
    "    # 3. Create Visualization Canvas\n",
    "    if save_evidence:\n",
    "        vis_img = img_8bit.copy()\n",
    "        vis_shadows = np.zeros_like(global_shadow_mask)\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # 4. Iterate Buildings\n",
    "    for idx, row in gdf.iterrows():\n",
    "        # A. Rasterize Building Footprint\n",
    "        geom = [row.geometry]\n",
    "        bld_mask = features.rasterize(geom, out_shape=img_8bit.shape[:2], transform=transform, fill=0, default_value=1, dtype=np.uint8)\n",
    "        \n",
    "        # B. Define Search Zone (Directional)\n",
    "        shadow_azimuth_rad = math.radians((CONFIG[\"SUN_AZIMUTH\"] + 180) % 360)\n",
    "        dist_px = CONFIG[\"SEARCH_DIST_M\"] / CONFIG[\"PIXEL_RES\"]\n",
    "        dx = int(dist_px * math.sin(shadow_azimuth_rad))\n",
    "        dy = int(dist_px * math.cos(shadow_azimuth_rad)) * -1\n",
    "        \n",
    "        M_shift = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "        shifted_mask = cv2.warpAffine(bld_mask, M_shift, (img_8bit.shape[1], img_8bit.shape[0]))\n",
    "        search_zone = cv2.subtract(shifted_mask, bld_mask)\n",
    "        \n",
    "        # C. Filter Shadows\n",
    "        valid_shadow = cv2.bitwise_and(global_shadow_mask, global_shadow_mask, mask=search_zone)\n",
    "        valid_shadow = cv2.subtract(valid_shadow, bld_mask * 255) # Clean Roofs\n",
    "        \n",
    "        # D. Measure (Parallel Scan)\n",
    "        px_len = parallel_line_scan(valid_shadow, CONFIG[\"SUN_AZIMUTH\"])\n",
    "        \n",
    "        if px_len > CONFIG[\"MIN_SHADOW_PX\"]:\n",
    "            # E. Physics\n",
    "            shadow_m = px_len * CONFIG[\"PIXEL_RES\"]\n",
    "            height_m = shadow_m * math.tan(math.radians(CONFIG[\"SUN_ELEVATION\"]))\n",
    "            floors = round(height_m / CONFIG[\"FLOOR_HEIGHT\"])\n",
    "            \n",
    "            results.append({\"id\": idx, \"height\": height_m, \"floors\": floors})\n",
    "            \n",
    "            # Add to evidence visualization\n",
    "            if save_evidence:\n",
    "                vis_shadows = cv2.bitwise_or(vis_shadows, valid_shadow)\n",
    "\n",
    "    # 5. Report & Save\n",
    "    if results:\n",
    "        print(f\"  ‚úÖ Found {len(results)} Buildings with Shadows.\")\n",
    "        for r in sorted(results, key=lambda x: x['floors'], reverse=True)[:3]:\n",
    "            print(f\"     - Bld {r['id']}: {r['floors']} Floors ({r['height']:.2f}m)\")\n",
    "        \n",
    "        if save_evidence:\n",
    "            save_evidence_image(base_id, img_8bit, gdf, vis_shadows, transform)\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è No significant shadows found.\")\n",
    "\n",
    "def save_evidence_image(base_id, img, gdf, shadow_mask, transform):\n",
    "    \"\"\"Generates the Red/Blue overlay image for the report.\"\"\"\n",
    "    os.makedirs(CONFIG[\"OUTPUT_DIR\"], exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    # Draw Buildings (Blue)\n",
    "    bld_mask = features.rasterize([(g, 1) for g in gdf.geometry], out_shape=img.shape[:2], transform=transform)\n",
    "    plt.imshow(bld_mask, cmap=ListedColormap(['none', 'cyan']), alpha=0.4, interpolation='none')\n",
    "    \n",
    "    # Draw Shadows (Red)\n",
    "    plt.imshow(shadow_mask, cmap=ListedColormap(['none', 'red']), alpha=0.6, interpolation='none')\n",
    "    \n",
    "    plt.title(f\"ShadowAudit Evidence: {base_id}\\nTsai Detection + Parallel Scan\", fontsize=14)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    save_path = os.path.join(CONFIG[\"OUTPUT_DIR\"], f\"evidence_{base_id}.png\")\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  üì∏ Evidence saved to: {save_path}\")\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Auto-find files\n",
    "    tif_files = sorted(glob.glob(os.path.join(CONFIG[\"IMG_DIR\"], \"*.tif\")))\n",
    "    geojson_files = sorted(glob.glob(os.path.join(CONFIG[\"LABEL_DIR\"], \"*.geojson\")))\n",
    "    \n",
    "    print(f\"üöÄ Starting ShadowAudit POC on {len(tif_files)} files...\")\n",
    "    \n",
    "    for t_path in tif_files[:]: # Run first 3 as demo\n",
    "        base_id = os.path.basename(t_path).split('_')[-1].replace('.tif', '')\n",
    "        g_path = next((g for g in geojson_files if base_id in g), None)\n",
    "        \n",
    "        if g_path:\n",
    "            process_tile(t_path, g_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
